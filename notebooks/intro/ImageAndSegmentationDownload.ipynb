{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume\n",
    "import pandas as pd\n",
    "from imageryclient import ImageryClient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_csv('data/soma_subgraph_synapses_spines_v185.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_source = \"precomputed://https://storage.googleapis.com/microns_public_datasets/pinky100_v0/son_of_alignment_v15_rechunked\"\n",
    "seg_source = \"precomputed://https://storage.googleapis.com/microns_public_datasets/pinky100_v185/seg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use cloudvolume to download data from these as if they were giant numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv = cloudvolume.CloudVolume(img_source, use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cv.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_cv[70000:70000+500, 70000:70000+500, 1025:1026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(img), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastremap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also download segmentation images the same way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_cv = cloudvolume.CloudVolume(seg_source)\n",
    "seg_cv.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg_cv[35000:35000+250, 35000:35000+250, 1025]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now because each pixel contains the ID of the object\n",
    "visualizing this as a normal image doesn't make sense\n",
    "fastremap can help you map these large IDs to smaller ones\n",
    "so visualization makes more sense as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may be much faster than np.unique\n",
    "uniq, cts = fastremap.unique(seg, return_counts=True) \n",
    "# relabel values from 1 and refit data type\n",
    "seg, remapping = fastremap.renumber(seg, in_place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remapping contains how these IDs were mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the list of IDs contained in this cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can visualize the remapped IDs like an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the segmentation full resolution is at half the resolution\n",
    "of the imagery so there isn't a 1-1 correspondance between pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape, img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ImageryClient from AnnotationFrameworkClient can help you think less\n",
    "about how to manage bounds between segmentation and images layers\n",
    "when you are trying to make cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic=ImageryClient(image_source = img_source,\n",
    "                 segmentation_source=seg_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets visualize the image and segmentation in the area\n",
    "that surrounds a random synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_num = 400\n",
    "post_id =syn_df.loc[syn_num,'post_root_id']\n",
    "pre_id = syn_df.loc[syn_num,'pre_root_id']\n",
    "syn=syn_df.loc[syn_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will pick out bounds with a 300 pixel (3.58*300 = 1027 nm) x,y region\n",
    "and 5 sections @40 nm in z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds=[[syn.ctr_pos_x_vx-150, syn.ctr_pos_y_vx-150, syn.ctr_pos_z_vx-2],\n",
    "        [syn.ctr_pos_x_vx+150, syn.ctr_pos_y_vx+150, syn.ctr_pos_z_vx+2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "this downloads the imagery as a numpy array and segmentation as a dictionary of arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgvol, segdict = ic.image_and_segmentation_cutout(bounds,\n",
    "                                                   split_segmentations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f ,ax = plt.subplots(4,3, figsize=(10,12))\n",
    "# lets loop over z sections\n",
    "for i in range(4):\n",
    "    # plot the images in column 0\n",
    "    ax[i, 0].imshow(np.squeeze(imgvol[:,:,i]),\n",
    "                    cmap=plt.cm.gray,\n",
    "                    vmax=255,\n",
    "                    vmin=0)\n",
    "    # plot the pre-synaptic mask in column 1\n",
    "    ax[i, 1].imshow(np.squeeze(segdict[post_id][:,:,i]))\n",
    "    # plot the post-synaptic mask in column 2\n",
    "    ax[i, 2].imshow(np.squeeze(segdict[pre_id][:,:,i]))\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function will save a series of PNG images that are exactly the same size\n",
    "so you can easily combine them as layers in Illustrator or photoshop\n",
    "to make a publication quality figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.save_image_and_segmentation_masks('synapse_test', bounds=bounds,\n",
    "                                     root_ids = [pre_id, post_id],\n",
    "                                     segmentation_colormap={pre_id:[255, 0,0,255], \n",
    "                                                            post_id:[0, 255, 0 ,255]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/synapse_figure.png \"Synapse Figure\")\n",
    "Here's an example image that used this output to make a figure highlighting the pre and post\n",
    "synaptic regions around this synapse "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_dev",
   "language": "python",
   "name": "analysis_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
