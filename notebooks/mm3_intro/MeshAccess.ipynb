{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python370jvsc74a57bd0e17c704ee36528c3cfcd7dcc3f7e33facab0a30a3c4c97ac2d81f69379006198",
   "display_name": "Python 3.7.0 64-bit ('micronsbinder2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Need to pip install annotationframeworkclient to repair mesh with pychunkedgraph\n"
     ]
    }
   ],
   "source": [
    "from caveclient import CAVEclient\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "import cloudvolume \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CAVEclient('minnie65_public_v117')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public_v117'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# to access dynamic meshes, you can query the segmentation source from the info client\n",
    "client.info.segmentation_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    }
   ],
   "source": [
    "# this can be used to initialize a cloudvolume object\n",
    "cv = cloudvolume.CloudVolume(client.info.segmentation_source(), progress=False)\n",
    "# which given a root_id can be used to get a mesh\n",
    "# cloud volume returns a dictionary with meshes as the keys\n",
    "mesh = cv.mesh.get(864691135474648896)[864691135474648896]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1698627, 3), (3388543, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# meshes are triangular meshes with vertices and faces\n",
    "# vertices are Nx3 x,y,z positions in nm\n",
    "# faces are Kx3 i,j,k indices into vertices that describe triangles\n",
    "mesh.vertices.shape, mesh.faces.shape\n"
   ]
  },
  {
   "source": [
    "Since downloading meshes can take some time, particularly for these dynamic meshes\n",
    "it is convient to cache them on disk. Also there a number of analytical techniques that you often want to accomplish on meshes, such as constructing a graph of the vertices and edges and calculating distances on them.  To facilitate this we developed a package called MeshParty. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# to enable a cache, create a MeshMeta object\n",
    "mm = trimesh_io.MeshMeta(cv_path = client.info.segmentation_source(),\n",
    "                         disk_cache_path='minnie65_v117_meshes',\n",
    "                         map_gs_to_https=True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "now i can get a mesh throught this and it will be cached in memory\n",
    "and in disk in case i need it again.\n",
    "restart the kernel and run the below cells again to see the difference.\n",
    "you'll find the mesh file saved as an hdf5 file in the \"minnie65_v117_meshes\"\n",
    "subdirectory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mm.mesh(seg_id=864691135474648896)"
   ]
  },
  {
   "source": [
    "The MeshParty object has more useful properties and attributes\n",
    "such as a scipy.csgraph sparse graph object (mesh.csgraph) and a networkx \n",
    "graph object (mesh.nxgraph) \n",
    "\n",
    "Read more about what you can do with MeshParty on its [Documentation](https://meshparty.readthedocs.io/en/latest/?badge=latest).\n",
    "\n",
    "In particular it lets you associate skeletons and annotations onto the mesh into a \"meshwork\" object.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The meshes that are available in the visualizaton on micronsexplorer are fast because they are static and all located in a single file, and because they were downsampled to 3 different levels of downsampling.  This makes them faster to interactive and more useful for many applications.  They also do not have a sense of the morphology of the neuron and so where there are locations of self contact, the mesh is merged. So depending on your application they made be preferrable to you.  Our reccomendations for general application area between the static and dynamic meshes are as follows, and the reasons why\n",
    "\n",
    "<h2>Dynamic</h2>\n",
    "* Morphological analysis (avoids self mergers)\n",
    "\n",
    "* Access historical mesh data during proofreading (not possible in flat)\n",
    "\n",
    "* Want to download with spatial querying (not presently implemented in cloudvolume)\n",
    "\n",
    "<h2>Static</h2>\n",
    "* Visualization (faster, downsampling available)\n",
    "* Somatic analysis (residual nucleus fragments exist)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note you need the use_https option here or else cloudvolume will try to use your google credentials\n",
    "# to access the bucket, and you don't have access to the bucket interface, just anonymous downloading\n",
    "cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns_phase3/minnie65/seg\", use_https=True)\n",
    "# this would also work if you wanted to grab it from the AWS bucket instead\n",
    "# cv = cloudvolume.CloudVolume(\"precomputed://s3://bossdb-open-data/microns/minnie/minnie65-flat-seg/\", use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cloud volume interface is the same\n",
    "mesh = cv.mesh.get(864691135474648896)[864691135474648896]\n",
    "# but its a faster initial download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((2017003, 3), (3976580, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# as you can see the meshes aren't exactly the same though\n",
    "mesh.vertices.shape, mesh.faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lod 0: n_verts: 2017003 n_faces: 3976580\n",
      "lod 1: n_verts: 575851 n_faces: 1121653\n",
      "lod 2: n_verts: 101194 n_faces: 192476\n",
      "lod 3: n_verts: 23099 n_faces: 42211\n"
     ]
    }
   ],
   "source": [
    "# in addition the flat meshes are available in 3 levels of detail\n",
    "# this covers two orders of magnitude of detail\n",
    "# this is what neuroglancer leverages to smartly load the data\n",
    "# at the resolution necessary to render the current scene.  \n",
    "for lod in range(4):\n",
    "    mesh = mesh = cv.mesh.get(864691135474648896, lod=lod)[864691135474648896]\n",
    "    print(f\"lod {lod}: n_verts: {mesh.vertices.shape[0]} n_faces: {mesh.faces.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}