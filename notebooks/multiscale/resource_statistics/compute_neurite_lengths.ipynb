{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing neurite lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "from lib import skel\n",
    "from lib import string2list as s2l\n",
    "\n",
    "from scipy.sparse import csgraph\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define volume properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xres = yres = 4 # in nm/px\n",
    "zres = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all pyramidal, interneuron, and glial segment IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the IDs from the soma subgraph and the consensus inhibitory cell table\n",
    "pyrs = pd.read_csv('data/soma_IDs/p100_pyr_soma_IDs_v185.csv',index_col=0)\n",
    "inhs = pd.read_csv('data/soma_IDs/p100_inh_soma_IDs_v185.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Euclidean_dist(p0,p1):\n",
    "    distvec = [(p0[q]-p1[q])**2 for q in range(len(p0))]\n",
    "    dist = np.sqrt(np.sum(distvec))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_path_lengths(segid,centroid,is_pyr=False):\n",
    "    \n",
    "    # With smoothed skeletons you should be able to access\n",
    "    # both pyramidal and inhibitory data in the same way\n",
    "    skelcurr = skel.read_smoothed_neuron_skel(segid)\n",
    "    skelbls = skel.read_smoothed_neuron_complbls(segid)\n",
    "    \n",
    "        \n",
    "    verts = skelcurr.vertices\n",
    "    edges = skelcurr.edges\n",
    "\n",
    "    \n",
    "    # Somatic nodes are classified so that nodes that are both\n",
    "    # <15 um from the soma centroid and \n",
    "    # <100 nodes from the soma centroid\n",
    "    # So we classify all nodes directly from their labels.\n",
    "    # classify remaining nodes as axons or dendrites\n",
    "    \n",
    "    nodes = [q for q in range(len(skelbls))]\n",
    "    somanodes = [q for q in nodes if skelbls[q] == 0]\n",
    "    axnodes = [q for q in nodes if skelbls[q] == 1]\n",
    "    dendnodes = [q for q in nodes if skelbls[q] in [2,3,4]]\n",
    "    \n",
    "    if centroid == None:\n",
    "        centroid_x = np.mean([verts[q][0] for q in somanodes])\n",
    "        centroid_y = np.mean([verts[q][1] for q in somanodes])\n",
    "        centroid_z = np.mean([verts[q][2] for q in somanodes])\n",
    "        centroid = [centroid_x,centroid_y,centroid_z]\n",
    "        \n",
    "    dists_centroid = [get_Euclidean_dist(verts[q],centroid) for q in nodes]\n",
    "    somaroot = nodes[np.argmin(dists_centroid)]\n",
    "    \n",
    "    \n",
    "    # print('numbers of nodes',len(axnodes),len(dendnodes))\n",
    "    axedges = []\n",
    "    dendedges = []\n",
    "    \n",
    "    for e in edges:\n",
    "        # explicitly remove any edges connecting nodes outside the soma threshold radius\n",
    "        # to nodes inside the radius\n",
    "        isinax = [q for q in e if q in axnodes]\n",
    "        isindend = [q for q in e if q in dendnodes]\n",
    "        if len(isinax) > 0:\n",
    "            axedges.append(e)\n",
    "        if len(isindend) > 0:\n",
    "            dendedges.append(e)\n",
    "            \n",
    "    # print('number of edges',len(axedges),len(dendedges))\n",
    "\n",
    "    # Make separate axonal and dendritic graphs\n",
    "    axgraph = nx.Graph()\n",
    "    dendgraph = nx.Graph()\n",
    "    \n",
    "    axgraph.add_nodes_from(axnodes)\n",
    "    ax_weighted_edges = []\n",
    "    for e in axedges:\n",
    "        wcurr = get_Euclidean_dist(verts[e[0]],verts[e[1]])\n",
    "        ax_weighted_edges.append((e[0],e[1],wcurr))\n",
    "    axgraph.add_weighted_edges_from(ax_weighted_edges)\n",
    "    \n",
    "    dendgraph.add_nodes_from(dendnodes)\n",
    "    dend_weighted_edges = []\n",
    "    for e in dendedges:\n",
    "        wcurr = get_Euclidean_dist(verts[e[0]],verts[e[1]])\n",
    "        dend_weighted_edges.append((e[0],e[1],wcurr))\n",
    "    dendgraph.add_weighted_edges_from(dend_weighted_edges)\n",
    "    \n",
    "    # Break the axonal and dendritic graphs into connected subgraph components\n",
    "    asgs = list(nx.connected_component_subgraphs(axgraph))\n",
    "    dsgs = list(nx.connected_component_subgraphs(dendgraph))\n",
    "    \n",
    "\n",
    "    \n",
    "    # Define containers for axon and dendritic path lengths\n",
    "    axdists = []\n",
    "    denddists = []\n",
    "    if is_pyr:\n",
    "        apical_denddists = []\n",
    "        basal_denddists = []\n",
    "        ambig_denddists = []\n",
    "    \n",
    "    # For each subgraph of a pyramidal cell (where skeletons are broken),\n",
    "    # find the node closest to the soma root node and add an edge between that\n",
    "    # node and the soma root in the full graph\n",
    "        # in this case, just find the leaf nodes in each connected subgraph\n",
    "        # and use dijkstra to find path lengths\n",
    "        for asg in asgs:\n",
    "            aleaves = [q for q in asg.nodes if asg.degree(q)==1]\n",
    "            # the source node is the one among these closest to the somaroot\n",
    "            asourceid = np.argmin([get_Euclidean_dist(verts[somaroot],verts[q]) for q in aleaves])\n",
    "            asource = aleaves[asourceid]\n",
    "            atargs = [aleaves[q] for q in range(len(aleaves)) if q != asourceid]\n",
    "            # print(asource,atargs) # debugging\n",
    "            for at in atargs:\n",
    "                acurr = nx.shortest_path_length(asg,source=asource,target=at,weight='weight')/1000.0 # convert to um\n",
    "                axdists.append(acurr)\n",
    "            \n",
    "        for dsg in dsgs:\n",
    "            dleaves = [q for q in dsg.nodes if dsg.degree(q)==1]\n",
    "            dsourceid = np.argmin([get_Euclidean_dist(verts[somaroot],verts[q]) for q in dleaves])\n",
    "            dsource = dleaves[dsourceid]\n",
    "            dtargs = [dleaves[q] for q in range(len(dleaves)) if q != dsourceid]\n",
    "            #print(dsource,dtargs) # debugging\n",
    "            for dt in dtargs:\n",
    "                dcurr = nx.shortest_path_length(dsg,source=dsource,target=dt,weight='weight')/1000.0 # convert to um\n",
    "                denddists.append(dcurr)\n",
    "                if skelbls[dt] == 2:\n",
    "                    basal_denddists.append(dcurr)\n",
    "                elif skelbls[dt] == 3:\n",
    "                    apical_denddists.append(dcurr)\n",
    "                elif skelbls[dt] == 4:\n",
    "                    ambig_denddists.append(dcurr)\n",
    "            \n",
    "    else:       \n",
    "        # Find axonal and dendritic leaf nodes\n",
    "        for asg in asgs:\n",
    "            aleaves = [q for q in asg.nodes if asg.degree(q)==1]\n",
    "            asourceid = np.argmin([get_Euclidean_dist(verts[somaroot],verts[q]) for q in aleaves])\n",
    "            asource = aleaves[asourceid]\n",
    "            atargs = [aleaves[q] for q in range(len(aleaves)) if q != asourceid]\n",
    "            for at in atargs:\n",
    "                acurr = nx.shortest_path_length(axgraph,source=asource,target=at,weight='weight')/1000.0 # convert to um\n",
    "                axdists.append(acurr)\n",
    "                \n",
    "        for dsg in dsgs:\n",
    "            dleaves = [q for q in dsg.nodes if dsg.degree(q)==1]\n",
    "            dsourceid = np.argmin([get_Euclidean_dist(verts[somaroot],verts[q]) for q in dleaves])\n",
    "            dsource = dleaves[dsourceid]\n",
    "            dtargs = [dleaves[q] for q in range(len(dleaves)) if q != dsourceid]\n",
    "            for dt in dtargs:\n",
    "                dcurr = nx.shortest_path_length(dendgraph,source=dsource,target=dt,weight='weight')/1000.0 # um\n",
    "                denddists.append(dcurr)\n",
    "                \n",
    "    if is_pyr:\n",
    "        return axdists,denddists,basal_denddists,apical_denddists,ambig_denddists\n",
    "    else:\n",
    "        return axdists,denddists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test case for debugging\n",
    "# p_start = pyrs.loc[1]['pt_root_id']\n",
    "# pscentroid_raw = s2l.string2list(pyrs.loc[1]['pt_position'])\n",
    "# pscentroid = [pscentroid_raw[1]*xres,pscentroid_raw[1]*yres,pscentroid_raw[2]*zres]\n",
    "# # print(pscentroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starttime = time.time()\n",
    "# # skel,lbls = get_process_path_lengths(p_start,centroid = pscentroid,is_pyr=True)\n",
    "# a,d,bd,ad,ambd = get_process_path_lengths(p_start,centroid = pscentroid,is_pyr=True)\n",
    "# endtime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(endtime-starttime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# pyr_neurite_info = pd.DataFrame(index=pyrs.index,columns=['axon_lengths_um','apical_dend_lengths_um','basal_dend_lengths_um','ambiguous_dend_lengths_um'])\n",
    "# for idx in tqdm(pyrs.index):\n",
    "#     rc = pyrs.loc[idx]\n",
    "#     rtid = rc['pt_root_id']\n",
    "#     centroidraw = s2l.string2list(rc['pt_position'])\n",
    "#     centroid = [centroidraw[0]*xres, centroidraw[1]*yres, centroidraw[2]*zres] # convert to nm\n",
    "#     neuritelengths = get_process_path_lengths(rtid,centroid,is_pyr=True)\n",
    "#     pyr_neurite_info.at[idx,'axon_lengths_um'] = neuritelengths[0]\n",
    "#     pyr_neurite_info.at[idx,'basal_dend_lengths_um'] = neuritelengths[1]\n",
    "#     pyr_neurite_info.at[idx,'apical_dend_lengths_um'] = neuritelengths[2]\n",
    "#     pyr_neurite_info.at[idx,'ambiguous_dend_lengths_um'] = neuritelengths[3]\n",
    "# end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyrs_w_neurites = pyrs.join(pyr_neurite_info)\n",
    "# pyrs_w_neurites.to_csv('data/neurite_lengths/20200818_p100_pyr_soma_ids_w_neurite_path_lengths_um_using_complbls_smoothed.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Time for excitatory neurons: {0:.02} seconds.'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process inhibitory interneurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [32:06<00:00, 104.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# start_time_2 = time.time()\n",
    "# inh_neurite_info = pd.DataFrame(index=inhs.index,columns=['axon_lengths_um','dendrite_lengths_um'])\n",
    "# for idx in tqdm(inhs.index):\n",
    "#     rc = inhs.loc[idx]\n",
    "#     rtid = rc['pt_root_id']\n",
    "#     axlengths,dendlengths = get_process_path_lengths(rtid,centroid=None,is_pyr=False)\n",
    "#     inh_neurite_info.at[idx,'axon_lengths_um'] = axlengths\n",
    "#     inh_neurite_info.at[idx,'dendrite_lengths_um'] = dendlengths\n",
    "# end_time_2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inhs_w_neurites = inhs.join(inh_neurite_info)\n",
    "# inhs_w_neurites.to_csv('data/neurite_lengths/20200818_p100_inh_soma_ids_w_ax_dend_path_lengths_um_smoothed.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inhibitory neurons: 1.9e+03 seconds.\n"
     ]
    }
   ],
   "source": [
    "# print('Time for inhibitory neurons: {0:.02} seconds.'.format(end_time_2 - start_time_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
